{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGkIGQBYDQBJ"
      },
      "outputs": [],
      "source": [
        "pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccBx_mym6lfs"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForTokenClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuKINvBG6h6D"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXr1P8PzCoXE"
      },
      "outputs": [],
      "source": [
        "pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U16kRLwaDMeD"
      },
      "outputs": [],
      "source": [
        "pip install seqeval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjNFthUgtOin"
      },
      "source": [
        "Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HLu94Kgs61J",
        "outputId": "57d32c06-f02d-4ae2-983f-7cff952d00e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEl3iFRlEOND"
      },
      "outputs": [],
      "source": [
        "PATH = \"/content/drive/MyDrive/tesi/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxM6EswktU02"
      },
      "source": [
        "Lettura dei dati ed estrazione dei token e dei dati (array di stringhe, array di id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvB7ZE5iyfJy"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "def read_data(file_path):\n",
        "    file_path = Path(file_path)\n",
        "    raw_text = file_path.read_text().strip()\n",
        "    raw_docs = re.split(r'\\n\\t?\\n', raw_text)\n",
        "    token_docs = []\n",
        "    tag_docs = []\n",
        "    for doc in raw_docs:\n",
        "        tokens = []\n",
        "        tags = []\n",
        "        for line in doc.split('\\n'):\n",
        "            token, tag = line.split('\\t')\n",
        "            tokens.append(token)\n",
        "            tags.append(int(tag))\n",
        "        token_docs.append(tokens)\n",
        "        tag_docs.append(tags)\n",
        "\n",
        "    return token_docs, tag_docs\n",
        "\n",
        "texts, tags = read_data(PATH + \"dataset/recipe_dataset.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLrihtbX06ni"
      },
      "source": [
        "Dichiarazione del dataset (encodings = testo tokenizzato con tokenizer, labels = tag numerici per gli encodings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7SDLuLe09gO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class RecipeDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()} #creo dizionario con l'encoding\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"labels\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QS4xD-4_heio"
      },
      "outputs": [],
      "source": [
        "\n",
        "id2label = {\n",
        "    0: \"B-ING\",\n",
        "    1: \"I-ING\",\n",
        "    2: \"B-QUANTITY\",\n",
        "    3: \"I-QUANTITY\",\n",
        "    4: \"B-UNIT\",\n",
        "    5: \"I-UNIT\",\n",
        "    6: \"B-STATE\",\n",
        "    7: \"I-STATE\",\n",
        "    8: \"B-PART\",\n",
        "    9: \"I-PART\",\n",
        "    10: \"B-EQUIPMENT\",\n",
        "    11: \"I-EQUIPMENT\",\n",
        "    12: \"B-ALT\",\n",
        "    13: \"I-ALT\",\n",
        "    14: \"O\"\n",
        "}\n",
        "label2id = {\n",
        "    \"B-ING\":0,\n",
        "    \"I-ING\":1,\n",
        "    \"B-QUANTITY\":2,\n",
        "    \"I-QUANTITY\":3,\n",
        "    \"B-UNIT\":4,\n",
        "    \"I-UNIT\":5,\n",
        "    \"B-STATE\":6,\n",
        "    \"I-STATE\":7,\n",
        "    \"B-PART\":8,\n",
        "    \"I-PART\":9,\n",
        "    \"B-EQUIPMENT\":10,\n",
        "    \"I-EQUIPMENT\":11,\n",
        "    \"B-ALT\":12,\n",
        "    \"I-ALT\":13,\n",
        "    \"O\":14\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv0v9Yo9B9y0"
      },
      "source": [
        "Definizione funzione allineamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Lq42uRyAEnj"
      },
      "outputs": [],
      "source": [
        "def align_labels_with_tokens(labels, word_ids):\n",
        "    new_labels = []\n",
        "    current_word = None\n",
        "    for word_id in word_ids:\n",
        "        if word_id != current_word:\n",
        "            # Start of a new word!\n",
        "            current_word = word_id\n",
        "            label = -100 if word_id is None else labels[word_id]\n",
        "            new_labels.append(label)\n",
        "        elif word_id is None:\n",
        "            # Special token\n",
        "            new_labels.append(-100)\n",
        "        else:\n",
        "            # Same word as previous token\n",
        "            label = labels[word_id]\n",
        "            if label % 2 == 0 and label != label2id[\"O\"]: #ATTENZIONE DIPENDE SE QUELLE PARI SOLO LE B O LE I\n",
        "              label+=1\n",
        "            new_labels.append(label)\n",
        "\n",
        "    return new_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8zzyDyJo0wx"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(texts, tags, tokenizer):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        texts, truncation=True, is_split_into_words=True, padding=True\n",
        "    )\n",
        "    new_labels = []\n",
        "    for i, labels in enumerate(tags):\n",
        "        word_ids = tokenized_inputs.word_ids(i)\n",
        "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = new_labels\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La4-CyvwCJGp"
      },
      "source": [
        "Allineamento e creazione del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uylxs7Ik696_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
        "tokenizer.is_fast\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9oqcUUXAFyB"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_texts, test_texts, train_tags, test_tags = train_test_split(texts, tags, test_size=.2) \n",
        "train_encs = tokenize_and_align_labels(train_texts, train_tags, tokenizer )\n",
        "test_encs = tokenize_and_align_labels(test_texts, test_tags, tokenizer )\n",
        "train_dataset = RecipeDataset(train_encs)\n",
        "eval_dataset = RecipeDataset(test_encs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Definizione funzioni di valutazione"
      ],
      "metadata": {
        "id": "PMnf1hWI49yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKaZTGm573ky"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "seqeval = evaluate.load(\"seqeval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQTmJYZL5lLU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "label_list = list(label2id.keys())\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twne1U8QN23a"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wgedeak37ujw"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\"bert-base-multilingual-uncased\", id2label=id2label, label2id=label2id,num_labels=len(id2label)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsQJR_t75pQH"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5CSGPXgN8BV"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=1,  # batch size per device during training\n",
        "    per_device_eval_batch_size=8,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=eval_dataset,             # evaluation dataset\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "model.save_pretrained(PATH + \"model_multi/\")\n",
        "tokenizer.save_pretrained(PATH + \"model_multi/\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}